import os
from dotenv import load_dotenv
from openai import OpenAI

# ğŸ” í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    load_dotenv()
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env ë˜ëŠ” Docker ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")

client = OpenAI(api_key=OPENAI_API_KEY)

# âœ… AI ì†Œë¹„ ë¶„ì„ ìš”ì•½ í•¨ìˆ˜
def analyze_data(
    real_name: str,
    data: dict,
    mode: str = "recent",
    start_date: str = "",
    end_date: str = ""
) -> str:
    # âœ… ë‚ ì§œ ì„¤ëª… êµ¬ì„±
    if mode == "recent":
        date_info = "ìµœê·¼ 7ì¼ê°„"
    elif mode == "range" and start_date and end_date:
        date_info = f"{start_date}ë¶€í„° {end_date}ê¹Œì§€"
    else:
        date_info = "ìµœê·¼ ê¸°ê°„"

    # âœ… ë¹ˆ ë°ì´í„° ì²˜ë¦¬
    if not data.get("expenses") and not data.get("emotions"):
        return "ë¶„ì„í•  ì†Œë¹„ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."

    # ğŸ§  í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    content = f"""
    ë‹¤ìŒì€ {real_name} ì‚¬ìš©ìì˜ {date_info} ì†Œë¹„ ê¸°ë¡ì…ë‹ˆë‹¤.

    â–¶ ì†Œë¹„ í•­ëª© ìš”ì•½:
    {data.get('expenses', {})}

    â–¶ ê°ì • ë¶„í¬ ìš”ì•½:
    {data.get('emotions', {})}

    ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì´ ì‚¬ìš©ìì˜ ì†Œë¹„ íŒ¨í„´ê³¼ ê°ì • ê²½í–¥ì„ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ 1~2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜.
    """

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì†Œë¹„ì™€ ê°ì • ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì•¼."},
                {"role": "user", "content": content.strip()}
            ]
        )

        result = response.choices[0].message.content.strip()
        print(f"âœ… AI ì†Œë¹„ ë¶„ì„ ê²°ê³¼:\n{result}")
        return result

    except Exception as e:
        print(f"âŒ OpenAI í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return "AI ë¶„ì„ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
